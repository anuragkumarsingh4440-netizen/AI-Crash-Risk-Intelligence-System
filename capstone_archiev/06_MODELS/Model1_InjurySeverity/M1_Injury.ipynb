{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76682,"status":"ok","timestamp":1768557763108,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"cSHPEGw5gW0c","outputId":"bcc1e55a-c4b8-4b36-9953-4f29a6894bfc","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Qa2myrbrkVb9","executionInfo":{"status":"ok","timestamp":1768557765360,"user_tz":-330,"elapsed":2250,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.model_selection import train_test_split\n","\n","# import StandardScaler to perform scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","# resample the dataset\n","from sklearn.utils import resample\n","from sklearn.utils import shuffle\n","\n","# import various functions from sklearn\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import StackingClassifier\n","\n","\n","# import the XGBoost function for classification\n","from xgboost import XGBClassifier\n","\n","import random\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OwHuqh3PkX_E","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"error","timestamp":1768557765686,"user_tz":-330,"elapsed":324,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}},"outputId":"046f8ac8-a187-4954-e7d1-04975c3269bf"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/0_dataset/3.FEATURED_ENGINEERING DATASET/Encoded_Data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4222308440.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/0_dataset/3.FEATURED_ENGINEERING DATASET/Encoded_Data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/0_dataset/3.FEATURED_ENGINEERING DATASET/Encoded_Data.csv'"]}],"source":["data = pd.read_csv('/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/0_dataset/3.FEATURED_ENGINEERING DATASET/Encoded_Data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AP6fJaTukX7f","executionInfo":{"status":"aborted","timestamp":1768557765683,"user_tz":-330,"elapsed":79456,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["df=data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79517,"status":"aborted","timestamp":1768557765745,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"ff5gtMH2109p","collapsed":true},"outputs":[],"source":["df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_gsPZvA1_Lf","executionInfo":{"status":"aborted","timestamp":1768557765746,"user_tz":-330,"elapsed":79517,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["df.drop(columns=['Unnamed: 0'],inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79517,"status":"aborted","timestamp":1768557765747,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"INgDRj_1kX4c"},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"UcTW_jydtRh5"},"source":["## Model-1: Master + Validation Split and Train–Test Split\n","### Step 1: Load Encoded Dataset\n","We load the complete encoded dataset which will be used to create splits.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79514,"status":"aborted","timestamp":1768557765748,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"LmjL-RjMkX12"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","target = \"Injury Severity\"\n","X = df.drop(columns=[target])\n","y = df[target]\n","\n","print(\"Dataset loaded:\", df.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"OvqzAjzzvf94"},"source":["## Step 2: Create Master (90%) and Validation (10%) Split\n","Master dataset is used for model training and testing.  \n","Validation dataset is for final unbiased evaluation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79512,"status":"aborted","timestamp":1768557765749,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"1sMd6Shzvi7T"},"outputs":[],"source":["X_major, X_val, y_major, y_val = train_test_split(\n","    X, y,\n","    test_size=0.10,\n","    stratify=y,\n","    random_state=42\n",")\n","\n","major_df = pd.concat([X_major, y_major], axis=1)\n","val_df   = pd.concat([X_val, y_val], axis=1)\n","\n","print(\"Master dataset:\", major_df.shape)\n","print(\"Validation dataset:\", val_df.shape)\n"]},{"cell_type":"code","source":["val_df.head(2)"],"metadata":{"id":"kq4KoPii_53P","executionInfo":{"status":"aborted","timestamp":1768557765750,"user_tz":-330,"elapsed":79511,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K9J0bcbKvtbO"},"source":["## Step 3: Save Master and Validation Files\n","Both files are saved in the Model-1 folder for later use.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79531,"status":"aborted","timestamp":1768557765772,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"TNX_QsSTkXzF"},"outputs":[],"source":["save_path = \"/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/08_MODELS/Model1_InjurySeverity/\"\n","\n","major_df.to_csv(save_path + \"model_1_master_data.csv\", index=False)\n","val_df.to_csv(save_path + \"model_1_validation_data.csv\", index=False)\n","\n","print(\"Saved model_1_master_data.csv and model_1_validation_data.csv\")\n"]},{"cell_type":"code","source":["df_master_data = pd.read_csv('/content/drive/MyDrive/CAPSTONE/CAPSTONE_PROJECT/08_MODELS/Model1_InjurySeverity/model_1_master_data.csv')\n"],"metadata":{"id":"uqjOIvbUXD8t","executionInfo":{"status":"aborted","timestamp":1768557765787,"user_tz":-330,"elapsed":79544,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_master_data.head(2)"],"metadata":{"id":"S5FBDHGGANMy","executionInfo":{"status":"aborted","timestamp":1768557765789,"user_tz":-330,"elapsed":79545,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y5UxpnCS4Q38"},"source":["# IMPORTANT  USER DEFINED FUNCTION"]},{"cell_type":"markdown","metadata":{"id":"Vdle0eoH5MY1"},"source":["### UNIVERSAL MODEL FUNCTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"494lCfwO4War","executionInfo":{"status":"aborted","timestamp":1768557765790,"user_tz":-330,"elapsed":79544,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["# ================================================================\n","# UNIVERSAL MODEL FUNCTION (simple + clear scaling logic)\n","# ================================================================\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import statsmodels.api as sm\n","\n","def run_model(model, X, y, test_size=0.20, scaled=False, threshold=0.5):\n","    \"\"\"\n","    scaled = True  → apply scaling on numeric columns\n","    scaled = False → no scaling\n","    model  = sklearn model OR \"stats\" for statsmodels logistic\n","    \"\"\"\n","\n","    # 1) Train–Test Split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=test_size, random_state=42, stratify=y\n","    )\n","\n","    # 2) Scaling if selected\n","    if scaled:\n","        scaler = StandardScaler()\n","        num_cols = X.select_dtypes(include='number').columns\n","\n","        X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n","        X_test[num_cols]  = scaler.transform(X_test[num_cols])\n","\n","    # 3) Statsmodels Logit\n","    if model == \"stats\":\n","        X_train_c = sm.add_constant(X_train)\n","        X_test_c  = sm.add_constant(X_test)\n","\n","        logit = sm.Logit(y_train, X_train_c).fit(disp=False)\n","\n","        yproba_train = logit.predict(X_train_c)\n","        yproba_test  = logit.predict(X_test_c)\n","\n","        ypred_train = (yproba_train >= threshold).astype(int)\n","        ypred_test  = (yproba_test >= threshold).astype(int)\n","\n","        return logit, X_train, X_test, y_train, y_test, ypred_train, ypred_test, yproba_train, yproba_test\n","\n","    # 4) Normal sklearn model\n","    model.fit(X_train, y_train)\n","\n","    ypred_train = model.predict(X_train)\n","    ypred_test  = model.predict(X_test)\n","\n","    yproba_train = model.predict_proba(X_train)[:,1]\n","    yproba_test  = model.predict_proba(X_test)[:,1]\n","\n","    return model, X_train, X_test, y_train, y_test, ypred_train, ypred_test, yproba_train, yproba_test\n"]},{"cell_type":"markdown","metadata":{"id":"z0a_IQ6n5gtp"},"source":["### METRICS FUNCTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdXEtHdY4WXM","executionInfo":{"status":"aborted","timestamp":1768557765791,"user_tz":-330,"elapsed":79544,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["# ================================================================\n","# METRICS FUNCTION (Train + Test separate + Binary/Multiclass safe)\n","# ================================================================\n","\n","import pandas as pd\n","from sklearn.metrics import (\n","    accuracy_score, recall_score, precision_score,\n","    f1_score, roc_auc_score, cohen_kappa_score,\n","    classification_report, confusion_matrix\n",")\n","\n","d = pd.DataFrame(columns=[\n","    'Model_Name','Split','Accuracy','Recall','Precision',\n","    'F1-Score','Kappa','ROC-AUC'\n","])\n","\n","def metrics(model_name, y_train, pred_train, proba_train,\n","            y_test, pred_test, proba_test):\n","\n","    global d\n","\n","    # Function to compute metrics for 1 split (train OR test)\n","    def compute(split_name, actual, predicted, proba):\n","\n","        unique_classes = len(pd.Series(actual).unique())\n","        is_binary = (unique_classes == 2)\n","        avg = \"binary\" if is_binary else \"weighted\"\n","\n","        acc  = accuracy_score(actual, predicted)\n","        rec  = recall_score(actual, predicted, average=avg)\n","        pre  = precision_score(actual, predicted, average=avg)\n","        f1   = f1_score(actual, predicted, average=avg)\n","        kap  = cohen_kappa_score(actual, predicted)\n","        auc  = roc_auc_score(actual, proba) if (is_binary and proba is not None) else None\n","\n","        # append to global dataframe\n","        d.loc[len(d)] = [model_name, split_name, acc, rec, pre, f1, kap, auc]\n","\n","        # print details\n","        print(f\"\\n================= {model_name} — {split_name} =================\")\n","        print(\"Classification Report:\")\n","        print(classification_report(actual, predicted))\n","\n","        print(\"Confusion Matrix:\")\n","        print(confusion_matrix(actual, predicted))\n","\n","        if auc is not None:\n","            print(\"ROC-AUC:\", auc)\n","\n","    # ---- TRAIN METRICS ----\n","    compute(\"Train\", y_train, pred_train, proba_train)\n","\n","    # ---- TEST METRICS ----\n","    compute(\"Test\", y_test, pred_test, proba_test)\n","\n","    return d"]},{"cell_type":"markdown","metadata":{"id":"HdNKZ8-R5x4x"},"source":["### Feature Importance Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yi3-hMGt4WUn","executionInfo":{"status":"aborted","timestamp":1768557765792,"user_tz":-330,"elapsed":79544,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["def fi(model, x, n_features=10):\n","    df_fi = pd.DataFrame({\n","        \"Feature\": x.columns,\n","        \"Importance\": model.feature_importances_\n","    })\n","    return df_fi.sort_values(by=\"Importance\", ascending=False).head(n_features)\n"]},{"cell_type":"markdown","metadata":{"id":"grwtwrBw6FlH"},"source":["### ROC Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5Dxnu7a4WR1","executionInfo":{"status":"aborted","timestamp":1768557765792,"user_tz":-330,"elapsed":79542,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["def plot_roc_plain(y_test, yproba_test):\n","    fpr, tpr, _ = roc_curve(y_test, yproba_test)\n","    plt.plot(fpr, tpr)\n","    plt.plot([0, 1], [0, 1])\n","    plt.xlabel(\"FPR\")\n","    plt.ylabel(\"TPR\")\n","    plt.title(\"ROC Curve\")\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ReXLDop2wGYL"},"source":["# MODEL BUILDING AND TRAINING\n"]},{"cell_type":"markdown","metadata":{"id":"-kk9abBo7py-"},"source":["### Logit Model (Statsmodels Logistic Regression)"]},{"cell_type":"markdown","metadata":{"id":"Pb9tHenN-fqi"},"source":["###  Why Statsmodels Logit Failed\n","\n","- Statsmodels **Logit requires a binary target** (only 0 and 1).\n","- Our Injury Severity column has **5 classes** (0, 1, 2, 3, 4).\n","- Because the target is **multi-class**, Logit cannot estimate probabilities in the 0–1 range.\n","- Therefore, Logit throws the error: *“endog must be in the unit interval.”*\n"]},{"cell_type":"markdown","metadata":{"id":"MnON2Q3Y_DxK"},"source":["## Logistic Regression (Sklearn) — Model Call\n","This model supports multi-class Injury Severity and works correctly without converting to binary.\n"]},{"cell_type":"code","source":["X = df_master_data.drop(columns=target)\n","y = df_master_data[target]"],"metadata":{"id":"u1STuvBAXi2T","executionInfo":{"status":"aborted","timestamp":1768557765793,"user_tz":-330,"elapsed":79540,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79539,"status":"aborted","timestamp":1768557765794,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"8aXyMwTwkXtY","collapsed":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Define model\n","log_reg = LogisticRegression(multi_class=\"multinomial\")\n","\n","# Run model using universal function\n","log_reg, X_train_lr, X_test_lr, y_train_lr, y_test_lr, ypred_train_lr, ypred_test_lr, yproba_train_lr, yproba_test_lr = run_model(\n","    model=log_reg,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=True\n",")\n","\n","# Correct metrics call\n","metrics(\n","    model_name=\"LogisticRegression\",\n","    y_train=y_train_lr,\n","    pred_train=ypred_train_lr,\n","    proba_train=yproba_train_lr,\n","    y_test=y_test_lr,\n","    pred_test=ypred_test_lr,\n","    proba_test=yproba_test_lr\n",")"]},{"cell_type":"markdown","metadata":{"id":"kJQv6ZtACj4J"},"source":["## Decision Tree Classifier — Model Call\n","Simple non-linear classifier, works well without scaling.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79538,"status":"aborted","timestamp":1768557765795,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"_b1kjehKkXqg"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# Define model\n","dt = DecisionTreeClassifier(random_state=42)\n","\n","# Run model using universal function\n","dt, X_train_dt, X_test_dt, y_train_dt, y_test_dt, ypred_train_dt, ypred_test_dt, yproba_train_dt, yproba_test_dt = run_model(\n","    model=dt,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=False    # Trees do NOT need scaling\n",")\n","\n","# Correct metrics function call\n","metrics(\n","    model_name=\"DecisionTree\",\n","    y_train=y_train_dt,\n","    pred_train=ypred_train_dt,\n","    proba_train=yproba_train_dt,\n","    y_test=y_test_dt,\n","    pred_test=ypred_test_dt,\n","    proba_test=yproba_test_dt\n",")"]},{"cell_type":"markdown","metadata":{"id":"CyO_9ZRtDsS9"},"source":["## Random Forest Classifier — Model Call\n","Ensemble of decision trees, robust to imbalance and noise.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79537,"status":"aborted","timestamp":1768557765795,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"P8F7HjlhkXn0","collapsed":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Define model\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Run model using universal function\n","rf, X_train_rf, X_test_rf, y_train_rf, y_test_rf, ypred_train_rf, ypred_test_rf, yproba_train_rf, yproba_test_rf = run_model(\n","    model=rf,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=False     # Trees & ensemble trees do NOT need scaling\n",")\n","\n","# Correct metrics function call\n","metrics(\n","    model_name=\"RandomForest\",\n","    y_train=y_train_rf,\n","    pred_train=ypred_train_rf,\n","    proba_train=yproba_train_rf,\n","    y_test=y_test_rf,\n","    pred_test=ypred_test_rf,\n","    proba_test=yproba_test_rf\n",")"]},{"cell_type":"markdown","metadata":{"id":"VxNXL_R7Dz6W"},"source":["## Gradient Boosting Classifier — Model Call\n","Boosting method that handles complex patterns; scaling not needed.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":79537,"status":"aborted","timestamp":1768557765796,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"},"user_tz":-330},"id":"-gqlr4s3kXk5","collapsed":true},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","# Define model\n","gb = GradientBoostingClassifier(random_state=42)\n","\n","# Run model\n","gb, X_train_gb, X_test_gb, y_train_gb, y_test_gb, ypred_train_gb, ypred_test_gb, yproba_train_gb, yproba_test_gb = run_model(\n","    model=gb,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=False      # Boosting trees DO NOT need scaling\n",")\n","\n","# Correct metrics function call\n","metrics(\n","    model_name=\"GradientBoosting\",\n","    y_train=y_train_gb,\n","    pred_train=ypred_train_gb,\n","    proba_train=yproba_train_gb,\n","    y_test=y_test_gb,\n","    pred_test=ypred_test_gb,\n","    proba_test=yproba_test_gb\n",")"]},{"cell_type":"markdown","metadata":{"id":"_ChSBQtKEEhg"},"source":["## AdaBoost Classifier — Model Call\n","Boosting model good for imbalanced classes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWPFAyc8kXiK","executionInfo":{"status":"aborted","timestamp":1768557765797,"user_tz":-330,"elapsed":79537,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}},"collapsed":true},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","# Define model\n","ada = AdaBoostClassifier(random_state=42)\n","\n","# Run universal model function\n","ada, X_train_ada, X_test_ada, y_train_ada, y_test_ada, ypred_train_ada, ypred_test_ada, yproba_train_ada, yproba_test_ada = run_model(\n","    model=ada,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=False   # Tree-based → NO scaling needed\n",")\n","\n","# Correct metrics call (train + test)\n","metrics(\n","    model_name=\"AdaBoost\",\n","    y_train=y_train_ada,\n","    pred_train=ypred_train_ada,\n","    proba_train=yproba_train_ada,\n","    y_test=y_test_ada,\n","    pred_test=ypred_test_ada,\n","    proba_test=yproba_test_ada\n",")"]},{"cell_type":"markdown","metadata":{"id":"t7NDl0ETESmD"},"source":["## XGBoost Classifier — Model Call\n","High-performance boosting model; does not require scaling.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hhi_bl-HkXfW","executionInfo":{"status":"aborted","timestamp":1768557765805,"user_tz":-330,"elapsed":79543,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","# Define model\n","xgb = XGBClassifier(\n","    random_state=42,\n","    use_label_encoder=False,\n","    eval_metric=\"mlogloss\"\n",")\n","\n","# Run model\n","xgb, X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb, ypred_train_xgb, ypred_test_xgb, yproba_train_xgb, yproba_test_xgb = run_model(\n","    model=xgb,\n","    X=X,\n","    y=y,\n","    test_size=0.20,\n","    scaled=False   # XGBoost does NOT require scaling\n",")\n","\n","# CORRECT metrics call\n","metrics(\n","    model_name=\"XGBoost\",\n","    y_train=y_train_xgb,\n","    pred_train=ypred_train_xgb,\n","    proba_train=yproba_train_xgb,\n","    y_test=y_test_xgb,\n","    pred_test=ypred_test_xgb,\n","    proba_test=yproba_test_xgb\n",")"]},{"cell_type":"markdown","source":["# Full Model Comparison & Inference Summary (Train vs Test)\n","\n","---\n","\n","## Table 1 — Performance Summary\n","\n","| Model               | Train Acc | Test Acc | Gap (Train−Test) | Overfitting Status       | Business Interpretation |\n","|--------------------|-----------|----------|------------------|---------------------------|-------------------------|\n","| Logistic Regression | 0.832     | 0.829    | 0.003            | ❌ No Overfitting         | Stable, reliable, interpretable baseline model. |\n","| Decision Tree       | 1.000     | 0.796    | 0.204            | ⚠️ Severe Overfitting     | Memorizes data; poor real-world performance. Avoid without pruning. |\n","| Random Forest       | 1.000     | 0.830    | 0.170            | ⚠️ Strong Overfitting     | High train accuracy but weak generalization; needs tuning. |\n","| Gradient Boosting   | 0.839     | 0.835    | 0.004            | ❌ No Overfitting         | Strong generalization; excellent production candidate. |\n","| AdaBoost            | 0.825     | 0.824    | 0.001            | ❌ No Overfitting         | Stable and reliable; consistent performance. |\n","| XGBoost             | 0.882     | 0.837    | 0.045            | ⚠️  Mild Overfitting       | High accuracy; needs tuning but very effective. |\n","\n","---\n","\n","## Table 2 — Overfitting/Underfitting Check\n","\n","| Model               | Status              | Reason |\n","|--------------------|----------------------|--------|\n","| Logistic Regression | Balanced             | Train ≈ Test, no overfit |\n","| Decision Tree       | Severe Overfitting   | Train = 100%, huge gap vs test |\n","| Random Forest       | Overfitting          | Train = 100%, lower test accuracy |\n","| Gradient Boosting   | Balanced             | Very small gap |\n","| AdaBoost            | Balanced             | Train and test same |\n","| XGBoost             | Mild Overfitting     | Slight drop in test |\n","\n","---\n","\n","## Table 3 — Business Interpretation\n","\n","| Model               | Business Impact | Use Case |\n","|--------------------|-----------------|----------|\n","| Logistic Regression | High interpretability; stable | Policy, audit reporting, explainable AI |\n","| Decision Tree       | Unstable; risky | Avoid for deployment |\n","| Random Forest       | Strong model but needs tuning | Post-tuning severity prediction |\n","| Gradient Boosting   | Best stability + accuracy | Real-time severity prediction |\n","| AdaBoost            | Very reliable | Safe deployment; low risk |\n","| XGBoost             | Highest accuracy | Best choice after tuning |\n","\n","---\n","\n","# Final Verdict (Short Summary)\n","\n","| Rank | Model             | Reason |\n","|------|------------------|--------|\n","| 1 | Gradient Boosting | Best balance of accuracy + stability |\n","| 2 | XGBoost           | Highest accuracy; slight overfit |\n","| 3 | AdaBoost          | Stable and consistent |\n","| 4    | Logistic Regression | Strong interpretable baseline |\n","| 5    | Random Forest     | Overfits; needs tuning |\n","| 6    | Decision Tree     | Too unstable |\n","\n","---"],"metadata":{"id":"G5TpSTDUhtip"}},{"cell_type":"markdown","source":["## Model Selection Summary for Further Tuning & Feature Alteration\n","\n","| Model              | Why Consider / Not Consider for Further Tuning |\n","|--------------------|------------------------------------------------|\n","| **XGBoost**     | **Best choice.** Highest Test F1-score and Kappa → strongest generalization. Handles high-dimensional (167 encoded features) data very well. Learns complex non-linear feature interactions. Highly sensitive to hyperparameter tuning and feature engineering, giving maximum upside. |\n","| Logistic Regression | Good baseline but **linear model**. Limited ability to capture complex interactions in heavily encoded feature space. Gains from tuning and feature alteration are usually marginal. |\n","| Decision Tree      | **Severe overfitting** (Train = 1.0). Very unstable with many features. Poor generalization → not suitable for reliable feature experimentation. |\n","| Random Forest      | Strong but **fully overfitted on train (1.0)**. Less responsive to fine feature engineering. Improvements from tuning are usually incremental compared to XGBoost. |\n","| Gradient Boosting  | Decent performance and stability, but lower Test F1 and Kappa than XGBoost. Less flexible and slower to scale with large feature sets. |\n","| AdaBoost           | Works better with weak learners and simpler feature spaces. Lower performance metrics and limited gains from extensive tuning with many encoded features. |\n","\n","### Final Decision\n","**Select XGBoost for further tuning and feature alteration** due to its superior generalization, robustness to high-dimensional data, and highest potential performance gains.\n"],"metadata":{"id":"esjJo43h7627"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RBxqgRskXcp","executionInfo":{"status":"aborted","timestamp":1768557765806,"user_tz":-330,"elapsed":79543,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ0N_diOkXZ4","executionInfo":{"status":"aborted","timestamp":1768557765807,"user_tz":-330,"elapsed":79543,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjg2MCfhkXXV","executionInfo":{"status":"aborted","timestamp":1768557765807,"user_tz":-330,"elapsed":79542,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8GlEqhnkXVA","executionInfo":{"status":"aborted","timestamp":1768557765808,"user_tz":-330,"elapsed":79541,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QPvmLGskXSb","executionInfo":{"status":"aborted","timestamp":1768557765871,"user_tz":-330,"elapsed":79601,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUYPH0nRkXQB","executionInfo":{"status":"aborted","timestamp":1768557765873,"user_tz":-330,"elapsed":79602,"user":{"displayName":"Siddhesh Sawant","userId":"05251367785737547550"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}